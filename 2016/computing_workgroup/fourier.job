# fourier.job
# An example Condor job file, courtesy of Isaac Sarver
# This file runs 100 instances of the executable "Spectral", which probably uses the process identifier to do something different for each instance.

# Name of executable (can be bash script for starting Mathematica as recommenced by Physics Department)
executable = Spectral
# Type of universe. OSX only supports vanilla. ccomp is on CentOS (Linux), which supports standard. Standard supports benchmarking so transfered and evicted jobs don't start over. To run in a standard universe compile with "condor_compile <normal compile command>". I have problems with this a bug that causes my programs to attempt illegal instructions. It is condor issue. Whatever you do, if your program takes too long to complete (half day or longer), you should consider strategies for recovery from early termination (an argument to denote where it left off, examination of output to figure out where it left off).
universe = standard
# Where should the cluster put output to the standard output. ($Cluster) inserts the run number.
Output = Spectral.$(Cluster).out
# Where should the cluster put output to the error stream.
error = Spectral.$(Cluster).err
# Where should the cluster put the log output. This is stuff generated by the cluster. It records when a job is submitted, (re)started execution, evicted, suspended, unsuspended, check pointed (standard only) and terminated/completed. It records a few other things here as well.
log = Spectral.$(Cluster).log
# When should condor send you an email? At last check, this feature is only available on ccomp. Metis makes an email but doesn't send it. The options are: Always (when a process checkpoints or ends), Complete (when a process successfully completes), Error (recommended, when a process terminates in an error state), Never. No option for whole job completion.
notification = Error
# Where to send that email
notify_user = example@tamu.edu
# Get the environment variables. DO THIS. On metis, it will evict your jobs every couple hours or so, and if it takes longer than that, they'll never finish.
getenv = True
# Start process in hold state. You should only do this if you want to do something to a submission before it starts. Examples include starting a subset of the processes to FORCE the scheduler to run certain processes first (ccomp doesn't always respect your priority options, metis does respect your choices) or remove a few of the processes.
hold=true
# Sets the processes default priority. Higher numbers are suppose to execute first. This only sets the priority of your processes and jobs relative to each other. You can't force your priority higher than someone else's using this. You can improve your priority by running fewer jobs or waiting before submission. This is only a temporary "fix" as your priority changes over time.
priority=1
# Tells the scheduler to only send these jobs to nodes with 4 or more cores. Not useful if you already split your program up using $(Process). You can have one process using 4 cores or 4 processes using 4 cores. If you don't split this way, you can use this to get the whole node, which can be useful if you are using OpenMP or other parallel processing API. However, it may force your process to wait for open nodes (usually not an issue). This doesn't seem to be an option on ccomp as the nodes seem to split into n nodes with 1 core rather than dynamically split like they are on metis.
request_cpus = 4

# Arguments to be sent to the process. ($Process) sends the process identifier to the program. Starts at 0. 100 is the number of processes working together. I use these two arguments to tell the program which parts of my table are to be calculated by a given process. The program then uses the process number to make its own output file that is not Spectral.$(Cluster).out, which I don't actually use. The rest of the arguments are application specific.
arguments = $(Process) 100 0 1 1.8
# How many of these processes are to be started. 100 in this case.
queue 100

# There are many other features available in the submit file. You can find the documentation at http://research.cs.wisc.edu/htcondor/manual/current/condor_submit.html.
# Start a job on the head node of choice by issuing the command "condor_submit Fourier_Job".
# You can find the default information about HTCondor at http://research.cs.wisc.edu/htcondor/manual/current/ref.html. I have yet to find a case of bad information in the default documentation.

# Physics condor cluster's head node is metis.physics.tamu.edu. You must be logging into it from a computer on campus. Use your credentials for webmail.physics.tamu.edu.
# Cyclotron condor cluster's head node appears to be all of the nodes. I submit from ccomp.tamu.edu. You must be logged into guardia.tamu.edu to log into ccomp.tamu.edu or any of the other node. Guardia has no login restrictions. If you issue bad credentials to any of the nodes 3 times, the submitting computer's IP address is banned for 24 hours. This includes guardia.tamu.edu logging into ccomp.tamu.edu. These credentials are specific to the cyclotron. If you are in a group attached to the cyclotron, talk to Robert Burch or Kris Hagel for login details.

# Physics condor cluster's license for Mathematica is on a per node basis. Each node can launch 8 (4 by the condor scheduler) Mathematica kernels simultaneously. The cyclotron condor cluster's license for Mathematica is on a cluster wide basis. It can launch a small number of Mathematica kernels simultaneously. It was reasonable once. But something went weird and that was lost.
